# -*- coding: utf-8 -*-
"""kmeans-Penguin.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Lc_kwN7iX1vmUs8wZ20w5wj-uK1UFFIe
"""

import pandas as pd
import numpy as np
import io 
import matplotlib.pyplot as plt
import seaborn as sns

# Uploading the Penguin.csv dataset onto google colab
from google.colab import files
uploaded = files.upload()

# Reading in file using Pandas
df = pd.read_csv(io.BytesIO(uploaded['penguins_size.csv']))

"""#1. Exploratory Data Analysis

"""

# Reading the initial data
df.info()

# Checking head of data
df.head()

# Printing countplot
sns.countplot(df['species'],palette='Set3');

# Pairing all the graphs
sns.pairplot(df,hue='species')

sns.heatmap(df.corr(), annot=True)

fig,axes=plt.subplots(4,1,figsize=(4,18))

# Checking boxplots to examine the differences

sns.boxplot(x=df.species,y=df.culmen_length_mm,ax=axes[1],palette='Set2')
sns.boxplot(x=df.species,y=df.culmen_depth_mm,ax=axes[2],palette='Set2')
sns.boxplot(x=df.species,y=df.body_mass_g,ax=axes[3],palette='Set2')
sns.boxplot(x=df.species,y=df.flipper_length_mm,ax=axes[0],palette='Set2')
# plt.tight_layout();

# Finding missing values
df.isnull().sum()

# Filling null values using length 

df['sex'].fillna(df['sex'].mode()[0], inplace=True)
#df['species'].fillna(df['species'].mode(), inplace=True)
df['culmen_length_mm'].fillna(df['culmen_length_mm'].mean(), inplace=True)
df['culmen_depth_mm'].fillna(df['culmen_depth_mm'].mean(), inplace=True)
df['flipper_length_mm'].fillna(df['flipper_length_mm'].mean(), inplace=True)
df['body_mass_g'].fillna(df['body_mass_g'].mean(), inplace=True)

df.isnull().sum()

# Seeing a missing value
df.sex.value_counts()

# Filling it out
df.loc[336,'sex'] = 'FEMALE'

"""#2. Creating a KMeans Model

"""

# Numerizing the Data for the species
#df['species'] = df['species'].map({'Adelie':0,'Gentoo':1,'Chinstrap':2})

X = pd.get_dummies(df)
X.head()

# Perform Scaling
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaled_X = scaler.fit_transform(X)

from sklearn.cluster import KMeans
from sklearn.metrics import confusion_matrix,classification_report,accuracy_score

model = KMeans(n_clusters=2)
cluster_labels = model.fit_predict(scaled_X)
cluster_labels

sns.heatmap(X.corr())

"""#3. Using for loop to create multiple models and then using the elbow method

"""

ssd = []

for i in range(2, 11):
  model = KMeans(n_clusters=i)
  model.fit(scaled_X)
  ssd.append(model.inertia_)

# Using the Elbow Method
plt.plot(range(2, 11), ssd, 'o--')
plt.xlabel("K-Value")
plt.ylabel("Sum Of Squared Distances")

"""On observation the K-Value to select using the elbow method is K=3"""

# 4
'''
The Result : The KMeans clustering model did not do that great going down to only
 250 for its SSD value when the cluster values was 10.
 Model Performance and accuracy was not that good
'''

